{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7d7751",
   "metadata": {},
   "source": [
    "# Model Experiments — AQI Predictor\n",
    "\n",
    "Interactive model comparison, hyperparameter tuning, and residual analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbbb02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from src.feature_pipeline.feature_store import get_training_data\n",
    "from src.training_pipeline.evaluate import (\n",
    "    compute_metrics, compare_models, plot_predictions_vs_actual\n",
    ")\n",
    "from src.config import RANDOM_STATE, TEST_SIZE\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "print('Libraries loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7666732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "X, y = get_training_data(use_hopsworks=False)\n",
    "print(f'Features: {X.shape}, Target: {y.shape}')\n",
    "\n",
    "# Time-based split\n",
    "split_idx = int(len(X) * (1 - TEST_SIZE))\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "print(f'Train: {len(X_train)}, Test: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6169e74b",
   "metadata": {},
   "source": [
    "## 1. Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84601cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training_pipeline.models.ridge_model import train as train_ridge, predict as predict_ridge\n",
    "\n",
    "ridge_model = train_ridge(X_train.values, y_train.values, tune=True)\n",
    "ridge_pred = predict_ridge(ridge_model, X_test.values)\n",
    "ridge_metrics = compute_metrics(y_test.values, ridge_pred)\n",
    "print(f'Ridge: {ridge_metrics}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5c47c",
   "metadata": {},
   "source": [
    "## 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274bf81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training_pipeline.models.random_forest import train as train_rf, predict as predict_rf\n",
    "\n",
    "rf_model = train_rf(X_train.values, y_train.values, tune=False)\n",
    "rf_pred = predict_rf(rf_model, X_test.values)\n",
    "rf_metrics = compute_metrics(y_test.values, rf_pred)\n",
    "print(f'Random Forest: {rf_metrics}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e901b5",
   "metadata": {},
   "source": [
    "## 3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09daf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training_pipeline.models.xgboost_model import train as train_xgb, predict as predict_xgb\n",
    "\n",
    "xgb_model = train_xgb(X_train.values, y_train.values,\n",
    "                       X_val=X_test.values, y_val=y_test.values, tune=False)\n",
    "xgb_pred = predict_xgb(xgb_model, X_test.values)\n",
    "xgb_metrics = compute_metrics(y_test.values, xgb_pred)\n",
    "print(f'XGBoost: {xgb_metrics}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d6a706",
   "metadata": {},
   "source": [
    "## 4. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe538fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'Ridge Regression': ridge_metrics,\n",
    "    'Random Forest': rf_metrics,\n",
    "    'XGBoost': xgb_metrics,\n",
    "}\n",
    "\n",
    "comparison = compare_models(results)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1259f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "preds = {'Ridge': ridge_pred, 'Random Forest': rf_pred, 'XGBoost': xgb_pred}\n",
    "for i, (name, pred) in enumerate(preds.items()):\n",
    "    axes[i].scatter(y_test.values, pred, alpha=0.4, s=10)\n",
    "    axes[i].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    axes[i].set_xlabel('Actual AQI')\n",
    "    axes[i].set_ylabel('Predicted AQI')\n",
    "    axes[i].set_title(name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a19ec90",
   "metadata": {},
   "source": [
    "## 5. Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b9de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals for best model\n",
    "best_name = min(results, key=lambda k: results[k]['rmse'])\n",
    "best_pred = preds[best_name.split()[0]] if best_name.split()[0] in preds else xgb_pred\n",
    "\n",
    "residuals = y_test.values - best_pred\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "axes[0].hist(residuals, bins=40, color='steelblue', edgecolor='white')\n",
    "axes[0].set_title(f'{best_name} — Residual Distribution')\n",
    "axes[0].set_xlabel('Residual')\n",
    "\n",
    "axes[1].scatter(best_pred, residuals, alpha=0.4, s=10)\n",
    "axes[1].axhline(0, color='red', linestyle='--')\n",
    "axes[1].set_title('Residuals vs Predicted')\n",
    "axes[1].set_xlabel('Predicted AQI')\n",
    "axes[1].set_ylabel('Residual')\n",
    "\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, plot=axes[2])\n",
    "axes[2].set_title('Q-Q Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
